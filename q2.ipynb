{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0986b331-4ddf-4549-ae61-c8372321a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files have been moved to the new train and validation folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define current root folder (your current folder structure with train/test inside category folders)\n",
    "current_root = 'images'\n",
    "\n",
    "# Define the new structure's root directory\n",
    "new_root = 'organized_data'\n",
    "\n",
    "# Define categories (adjust according to your categories)\n",
    "categories = ['Coast', 'Forest', 'Highway', 'Kitchen', 'Mountain', \n",
    "              'Office', 'Store', 'Street', 'Suburb']\n",
    "\n",
    "# Create the new folder structure for train and validation\n",
    "for category in categories:\n",
    "    os.makedirs(os.path.join(new_root, 'train', category), exist_ok=True)\n",
    "    os.makedirs(os.path.join(new_root, 'validation', category), exist_ok=True)\n",
    "\n",
    "# Move files from the old structure to the new structure\n",
    "for category in categories:\n",
    "    # Define source paths\n",
    "    old_train_dir = os.path.join(current_root, category, 'train')\n",
    "    old_test_dir = os.path.join(current_root, category, 'test')\n",
    "    \n",
    "    # Define destination paths\n",
    "    new_train_dir = os.path.join(new_root, 'train', category)\n",
    "    new_validation_dir = os.path.join(new_root, 'validation', category)\n",
    "    \n",
    "    # Move the training images to the new train directory\n",
    "    if os.path.exists(old_train_dir):\n",
    "        for filename in os.listdir(old_train_dir):\n",
    "            if filename.endswith('.jpg'):  # Assuming all files are images\n",
    "                shutil.move(os.path.join(old_train_dir, filename), os.path.join(new_train_dir, filename))\n",
    "    \n",
    "    # Move the test images to the new validation directory\n",
    "    if os.path.exists(old_test_dir):\n",
    "        for filename in os.listdir(old_test_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                shutil.move(os.path.join(old_test_dir, filename), os.path.join(new_validation_dir, filename))\n",
    "\n",
    "print(\"Files have been moved to the new train and validation folders.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2372bf-40b1-4177-b6da-6e9b1a30ec83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 902 images belonging to 9 classes.\n",
      "Found 1698 images belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 09:01:03.253530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.257510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.257659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.257950: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-18 09:01:03.258309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.258445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.258546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.646015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.646244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.646394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-10-18 09:01:03.646528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6654 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2024-10-18 09:01:04.035838: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-18 09:01:04.914716: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2024-10-18 09:01:05.292245: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-18 09:01:05.292511: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-18 09:01:05.292528: W tensorflow/stream_executor/gpu/asm_compiler.cc:77] Couldn't get ptxas version string: Internal: Couldn't invoke ptxas --version\n",
      "2024-10-18 09:01:05.292863: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-10-18 09:01:05.292908: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-10-18 09:01:06.057720: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:06.057804: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:06.701717: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:06.701770: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.46GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:06.701822: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:06.701849: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:08.016751: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:08.016797: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.60GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:08.350726: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2024-10-18 09:01:08.350818: W tensorflow/core/common_runtime/bfc_allocator.cc:272] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 17s 798ms/step - loss: 2.1712 - accuracy: 0.1241 - val_loss: 2.0528 - val_accuracy: 0.2356\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 8s 555ms/step - loss: 1.8449 - accuracy: 0.3377 - val_loss: 1.7398 - val_accuracy: 0.4081\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 8s 567ms/step - loss: 1.4643 - accuracy: 0.5072 - val_loss: 1.4696 - val_accuracy: 0.4976\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 8s 562ms/step - loss: 1.1730 - accuracy: 0.6295 - val_loss: 1.4108 - val_accuracy: 0.5216\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 8s 547ms/step - loss: 0.9637 - accuracy: 0.6814 - val_loss: 1.3937 - val_accuracy: 0.5553\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 8s 570ms/step - loss: 0.9056 - accuracy: 0.7143 - val_loss: 1.1566 - val_accuracy: 0.6022\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 8s 575ms/step - loss: 0.6947 - accuracy: 0.7697 - val_loss: 1.1252 - val_accuracy: 0.6184\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 8s 563ms/step - loss: 0.5272 - accuracy: 0.8294 - val_loss: 1.3757 - val_accuracy: 0.5739\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 8s 547ms/step - loss: 0.3592 - accuracy: 0.8747 - val_loss: 1.1319 - val_accuracy: 0.6556\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 8s 576ms/step - loss: 0.3524 - accuracy: 0.8842 - val_loss: 1.1547 - val_accuracy: 0.6490\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 8s 569ms/step - loss: 0.1876 - accuracy: 0.9463 - val_loss: 1.3516 - val_accuracy: 0.6484\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 8s 549ms/step - loss: 0.0752 - accuracy: 0.9761 - val_loss: 1.4358 - val_accuracy: 0.6556\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 8s 550ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 1.7526 - val_accuracy: 0.6364\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.0228 - accuracy: 0.9964 - val_loss: 1.6744 - val_accuracy: 0.6599\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 8s 561ms/step - loss: 0.0124 - accuracy: 0.9988 - val_loss: 1.8045 - val_accuracy: 0.6556\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 7s 568ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 2.0057 - val_accuracy: 0.6526\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 7s 489ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.1890 - val_accuracy: 0.6514\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 7s 506ms/step - loss: 0.0277 - accuracy: 0.9905 - val_loss: 2.0203 - val_accuracy: 0.6629\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 7s 500ms/step - loss: 0.0092 - accuracy: 0.9988 - val_loss: 1.9621 - val_accuracy: 0.6478\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 7s 487ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 1.8187 - val_accuracy: 0.6833\n",
      "27/27 [==============================] - 5s 183ms/step - loss: 1.8225 - accuracy: 0.6808\n",
      "Test accuracy: 0.6808\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set up directories and image size\n",
    "train_dir = 'organized_data/train'\n",
    "test_dir = 'organized_data/validation'\n",
    "img_size = 224\n",
    "batch_size = 64  # Keep the batch size smaller for the smaller dataset\n",
    "\n",
    "# Define the image data generators for loading the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# VGG16-inspired model\n",
    "model = models.Sequential()\n",
    "\n",
    "# First convolutional stage (2 Conv layers + MaxPooling)\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Second convolutional stage (2 Conv layers + MaxPooling)\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Third convolutional stage (3 Conv layers + MaxPooling)\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))  # Reduced from VGG's 4096\n",
    "\n",
    "# Output layer with softmax for 9 categories\n",
    "model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=20,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
