{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c45de6e-65e2-4beb-b5ea-ddec9cb4b7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 902 images belonging to 9 classes.\n",
      "Found 1698 images belonging to 9 classes.\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 6s 416ms/step - loss: 1.9518 - accuracy: 0.2745 - val_loss: 1.2819 - val_accuracy: 0.6791\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 5s 379ms/step - loss: 1.0978 - accuracy: 0.6289 - val_loss: 0.5265 - val_accuracy: 0.8365\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 5s 396ms/step - loss: 0.6861 - accuracy: 0.7733 - val_loss: 0.3992 - val_accuracy: 0.8966\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 6s 414ms/step - loss: 0.4144 - accuracy: 0.8496 - val_loss: 0.3222 - val_accuracy: 0.8798\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 0.3163 - accuracy: 0.8842 - val_loss: 0.2374 - val_accuracy: 0.9279\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 5s 387ms/step - loss: 0.2087 - accuracy: 0.9320 - val_loss: 0.1968 - val_accuracy: 0.9411\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 5s 388ms/step - loss: 0.1761 - accuracy: 0.9379 - val_loss: 0.1681 - val_accuracy: 0.9489\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 5s 384ms/step - loss: 0.1509 - accuracy: 0.9606 - val_loss: 0.2048 - val_accuracy: 0.9315\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 6s 407ms/step - loss: 0.1511 - accuracy: 0.9415 - val_loss: 0.1874 - val_accuracy: 0.9327\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 6s 396ms/step - loss: 0.0942 - accuracy: 0.9690 - val_loss: 0.1494 - val_accuracy: 0.9513\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 5s 386ms/step - loss: 0.1231 - accuracy: 0.9654 - val_loss: 0.1840 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 5s 390ms/step - loss: 0.0705 - accuracy: 0.9785 - val_loss: 0.1463 - val_accuracy: 0.9567\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 5s 395ms/step - loss: 0.0415 - accuracy: 0.9893 - val_loss: 0.1429 - val_accuracy: 0.9603\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.0387 - accuracy: 0.9905 - val_loss: 0.1323 - val_accuracy: 0.9663\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 6s 413ms/step - loss: 0.0336 - accuracy: 0.9928 - val_loss: 0.1391 - val_accuracy: 0.9609\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 5s 383ms/step - loss: 0.0395 - accuracy: 0.9916 - val_loss: 0.1292 - val_accuracy: 0.9615\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 5s 393ms/step - loss: 0.0284 - accuracy: 0.9952 - val_loss: 0.1836 - val_accuracy: 0.9393\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 5s 397ms/step - loss: 0.0233 - accuracy: 0.9964 - val_loss: 0.1603 - val_accuracy: 0.9537\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 5s 381ms/step - loss: 0.0289 - accuracy: 0.9905 - val_loss: 0.1243 - val_accuracy: 0.9663\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 6s 407ms/step - loss: 0.0187 - accuracy: 0.9964 - val_loss: 0.1803 - val_accuracy: 0.9525\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 12s 662ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.1776 - val_accuracy: 0.9561\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 9s 639ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 0.1563 - val_accuracy: 0.9579\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 9s 669ms/step - loss: 0.0075 - accuracy: 0.9988 - val_loss: 0.1599 - val_accuracy: 0.9609\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.1593 - val_accuracy: 0.9543\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 9s 638ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1374 - val_accuracy: 0.9651\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 9s 632ms/step - loss: 0.0105 - accuracy: 0.9952 - val_loss: 0.1709 - val_accuracy: 0.9573\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 9s 639ms/step - loss: 0.0151 - accuracy: 0.9940 - val_loss: 0.1826 - val_accuracy: 0.9513\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 9s 636ms/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.2114 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 9s 634ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.1279 - val_accuracy: 0.9663\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 9s 667ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.1297 - val_accuracy: 0.9657\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 9s 633ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.1380 - val_accuracy: 0.9669\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 9s 627ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1330 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 8s 607ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9657\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 9s 639ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9663\n",
      "27/27 [==============================] - 3s 120ms/step - loss: 0.1254 - accuracy: 0.9670\n",
      "Transfer Learning with VGG16 Test Accuracy after Fine-Tuning: 0.9670\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up directories and image size\n",
    "train_dir = 'organized_data/train'\n",
    "test_dir = 'organized_data/validation'\n",
    "img_size = 224  # Standard VGG16 input size\n",
    "batch_size = 64\n",
    "\n",
    "# Define the image data generators for loading the dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)  # Added horizontal flip for augmentation\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Load the VGG16 model with pre-trained weights, excluding the top layer\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "\n",
    "# Freeze all layers of the base model first\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Unfreeze the last 4 layers for fine-tuning\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom classification layers on top of VGG16\n",
    "model = models.Sequential()\n",
    "model.add(base_model)  # Add the pre-trained VGG16 base\n",
    "model.add(layers.GlobalAveragePooling2D())  # Global average pooling instead of flattening\n",
    "model.add(layers.Dense(512, activation='relu'))  # Fully connected layer with 512 units\n",
    "model.add(layers.Dropout(0.5))  # Adding dropout for regularization\n",
    "model.add(layers.Dense(9, activation='softmax'))  # New output layer with 9 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for learning rate scheduling and early stopping\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=20,  # Initial epochs\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Fine-tune the entire model by unfreezing all layers for additional training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model with a lower learning rate for fine-tuning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune with additional epochs\n",
    "fine_tune_history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=20,  # Fine-tuning epochs\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test set for top-1 accuracy\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Transfer Learning with VGG16 Test Accuracy after Fine-Tuning: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd17daa-1cd7-4157-a402-f6c52cea2f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
